1.
Obviously, a computer is nothing more than an automaton. And on a computer, everything is represented in binary.
When some input data is handled at any point throughout the execution of a program, the context of the program decides what the data represents. It is basically a set of binary bits in terms of hardware (or even more fundamentally, a set of differing voltages). The context in which these fragments appear is what gives them meaning.
When you press a key on a keyboard, the switches and the small CPU within turn the switch press into a key code, which is simply a pattern of binary bits that indicates whether you pushed the ‘a' key or the space bar. The keyboard then saves numerous entries in a tiny memory and sends a signal to the USB bus that data is available. The main CPU receives an interrupt signal from the USB hardware, informing it that something requires attention. In response, it runs a short software that determines what needs to be addressed. In this case it is to service new data on the USB bus. 
Since it can tell which USB device wanted attention (the USB hardware has a physical register to store that data that the CPU can read), it has some context, and therefore knows which driver (a program which handles a specific device) it needs to run to process the data, in this case the keyboard driver. The keyboard driver links with the keyboard and retrieves the keypress data that has been queued. The keyboard driver is basically a piece of code that has been created to do one thing: receive data from a USB device with a specific USB identifier, do some conversions on it, and then inform another piece of code that keyboard input is available.

2. 
Data packets are a collection of information units that are combined into a single set for transmission over the Internet. To relay information, any data that needs to be conveyed from one system to another must first be broken down into smaller parts. These parts are reassembled to become readable once they reach the destination.
Internet Protocol (IP)-based systems utilize packets of data to communicate with one another across the Internet. Depending on the protocol used for transmission, a data packet is referred to as a "block," "datagram," or "frame."
Sending a photo image to a buddy using an app like IMessage is an example of the data packet procedure.
Before being sent, the image is separated into small bits, which happens in the background, of course. After that, your friend just sees the reassembled image.
Bandwidth, Network Congestion, Packet Loss, Jitters, and Web Browsers are all factors that affect data packet delivery.
The size of the Internet pipeline available to a user is referred to as bandwidth. It determines how much data a user can send at a given moment. In the case of data packets, bandwidth refers to the maximum number of packets that a user may fit into his or her accessible pipeline. In other words, the larger the bandwidth, the more data packets can be accommodated and the more efficient the transmission.
The slower the transmission becomes as the amount of data packets flowing through an Internet pipeline grows.
When data is lost during transmission, it is referred to as a packet loss.
Jitters are network data packet emissions that are erratic.
Receiving packets and arranging them into web pages that visitors see is the job of a web browser. A browser should be able to process up to eight data packets at once. 
The usage of data packets guarantees that information is transferred reliably and efficiently. The utilization of data packets is critical since it allows networks to operate more quickly. Users would no longer have to worry about their communications becoming stuck in transit to their intended receivers.

3.
The amount of data transmitted through a network in a certain time period is referred to as the data rate. It refers to the rate at which data is moved from one device to another or between a computer and a peripheral device. Megabits per second (Mbps) or Megabytes per second (MBPS) are the most used units of measurement (MBps). For example, if the bandwidth is 100 Mbps but the data rate is 50 Mbps, the greatest amount of data that can be transferred is 100 Mb, but the channel is only transferring 50 Mb per second.
Bandwidth is the maximum amount of data that can be transferred in a given amount of time. It refers to the network's or transmission medium's data carrying capability. It is the maximum quantity of data that can be transferred per second over a network in basic terms. Bits per second (bps), Megabits per second (Mbps), and Gigabits per second (GBPS) are the most used units of measurement (Gbps).
Throughput is the overall effective transmission rate, which takes into account factors such as transmission overhead, protocol inefficiencies, and maybe competing traffic. It is usually measured at a network layer higher than the data rate.

4.
A datagram is a self-contained message with source and destination addresses given in the header. It is mostly used for wireless communication.
The concept behind datagrams is quite simple. You simply add enough information in each packet to allow any switch to select how to transport it to its destination. Every packet, in other words, carries the whole destination address.
Packet headers in the datagram-forwarding model of packet delivery contain a destination address. It is the responsibility of the intervening switches or routers to examine this address and route the message to the proper destination.
This is performed in datagram forwarding by providing each switch with a forwarding database of (destination,next hop) pairs. When a packet arrives, the switch searches its forwarding table for the next hop information: the immediate-neighbor address – or interface – to which the packet should be transferred to move it one step closer to its final destination. A forwarding table's next hop value is a single entry; each switch is solely responsible for one step in the packet's journey. If all goes well, the network of switches will be able to send the packet to its final destination one hop at a time.
The packet destination addresses do not have to perfectly match the “destination” entries in the forwarding table. For IP routing, however, the table's "destination" entries will correlate to IP address prefixes, resulting in significant space savings. The switch must be able to determine the next hop by performing a lookup operation using its forwarding table and the destination address in the receiving packet.

5.
Algorithms are, in essence, a set of instructions that are followed step by step to accomplish a goal or solve a problem. A cake recipe, for example, could be thought of as an algorithm for baking a cake.
Algorithms in computing give computers with a step-by-step roadmap to complete tasks. They are made up of a detailed set of instructions that detail how to perform a task. They serve as the foundation for programming, allowing devices such as computers, smartphones, and websites to function and make decisions.
Input and output are how computer algorithms work. They take the information as input and apply each step of the algorithm to it to produce an output.
A search engine, for example, is an algorithm that accepts a search query as input and searches its database for items that match the words in the query. The findings are then output.
Algorithms can be simply seen as flowcharts.
The data generates a series of processes and queries that must be addressed in a specific order. The generated result is the outcome when each step of the flowchart is completed.
Algorithms are employed in every aspect of computing and information technology. They can manipulate and analyze data in a variety of ways, as well as conduct calculations and actions.
Automation software is an excellent illustration of algorithms in action. This is since automation completes tasks by according to a set of rules. An algorithm is created by these rules.
Technology will only improve and evolve. Algorithms will always be at the heart of these technologies, dictating what they do and how they do it if coding and programming are used.

6.
The topology of your network refers to how nodes, devices, and connections are physically or logically connected to one another. Consider your network to be a city, with the topology serving as the road map. There are numerous methods to arrange and manage a network, just as there are different ways to arrange and maintain a city—for example, ensuring that avenues and boulevards can enable movement between the busiest parts of town. Each has benefits and drawbacks, and depending on your company's needs, different arrangements can provide you with a higher level of connectivity and security.
Physical and logical topologies are the two types of network topology. The physical links and interconnections between nodes and the network—the wires, cables, and so on—are referred to as physical network topology, as the name suggests. Logical network topology is more abstract and strategic, referring to the conceptual knowledge of how and why the network is set up the way it is, as well as how data flows across it.
For a variety of reasons, the layout of your network is critical. Above all, it is critical to the operation and performance of your network. Choosing the correct topology for your company's operational model can improve performance while also making it easier to discover faults, rectify mistakes, and allocate resources more effectively across the network to ensure optimal network health. A streamlined and properly managed network topology can increase energy and data efficiency, which can in turn help to reduce operational and maintenance costs.
